{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if not tf.test.is_gpu_available():\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NORM_DECAY = 0.997\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "L2_WEIGHT_DECAY = 2e-4\n",
    "\n",
    "\n",
    "def identity_building_block(input_tensor,\n",
    "                            kernel_size,\n",
    "                            filters,\n",
    "                            stage,\n",
    "                            block,\n",
    "                            training=None):\n",
    "  \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "\n",
    "  Arguments:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of\n",
    "        middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: current block label, used for generating layer names\n",
    "    training: Only used if training keras model with Estimator.  In other\n",
    "      scenarios it is handled automatically.\n",
    "\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "  filters1, filters2 = filters\n",
    "  if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = tf.keras.layers.Conv2D(filters1, kernel_size,\n",
    "                             padding='same',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             bias_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             name=conv_name_base + '2a')(input_tensor)\n",
    "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                         name=bn_name_base + '2a',\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(\n",
    "                                             x, training=training)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  x = tf.keras.layers.Conv2D(filters2, kernel_size,\n",
    "                             padding='same',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             bias_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             name=conv_name_base + '2b')(x)\n",
    "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                         name=bn_name_base + '2b',\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(\n",
    "                                             x, training=training)\n",
    "\n",
    "  x = tf.keras.layers.add([x, input_tensor])\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "def conv_building_block(input_tensor,\n",
    "                        kernel_size,\n",
    "                        filters,\n",
    "                        stage,\n",
    "                        block,\n",
    "                        strides=(2, 2),\n",
    "                        training=None):\n",
    "  \"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "  Arguments:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of\n",
    "        middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: current block label, used for generating layer names\n",
    "    strides: Strides for the first conv layer in the block.\n",
    "    training: Only used if training keras model with Estimator.  In other\n",
    "      scenarios it is handled automatically.\n",
    "\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "\n",
    "  Note that from stage 3,\n",
    "  the first conv layer at main path is with strides=(2, 2)\n",
    "  And the shortcut should have strides=(2, 2) as well\n",
    "  \"\"\"\n",
    "  filters1, filters2 = filters\n",
    "  if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = tf.keras.layers.Conv2D(filters1, kernel_size, strides=strides,\n",
    "                             padding='same',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             bias_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             name=conv_name_base + '2a')(input_tensor)\n",
    "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                         name=bn_name_base + '2a',\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(\n",
    "                                             x, training=training)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  x = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             bias_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             name=conv_name_base + '2b')(x)\n",
    "  x = tf.keras.layers.BatchNormalization(axis=bn_axis,\n",
    "                                         name=bn_name_base + '2b',\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(\n",
    "                                             x, training=training)\n",
    "\n",
    "  shortcut = tf.keras.layers.Conv2D(filters2, (1, 1), strides=strides,\n",
    "                                    kernel_initializer='he_normal',\n",
    "                                    kernel_regularizer=\n",
    "                                    tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                    bias_regularizer=\n",
    "                                    tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                                    name=conv_name_base + '1')(input_tensor)\n",
    "  shortcut = tf.keras.layers.BatchNormalization(\n",
    "      axis=bn_axis, name=bn_name_base + '1',\n",
    "      momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(\n",
    "          shortcut, training=training)\n",
    "\n",
    "  x = tf.keras.layers.add([x, shortcut])\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "def resnet_block(input_tensor,\n",
    "                 size,\n",
    "                 kernel_size,\n",
    "                 filters,\n",
    "                 stage,\n",
    "                 conv_strides=(2, 2),\n",
    "                 training=None):\n",
    "  \"\"\"A block which applies conv followed by multiple identity blocks.\n",
    "\n",
    "  Arguments:\n",
    "    input_tensor: input tensor\n",
    "    size: integer, number of constituent conv/identity building blocks.\n",
    "    A conv block is applied once, followed by (size - 1) identity blocks.\n",
    "    kernel_size: default 3, the kernel size of\n",
    "        middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    conv_strides: Strides for the first conv layer in the block.\n",
    "    training: Only used if training keras model with Estimator.  In other\n",
    "      scenarios it is handled automatically.\n",
    "\n",
    "  Returns:\n",
    "    Output tensor after applying conv and identity blocks.\n",
    "  \"\"\"\n",
    "\n",
    "  x = conv_building_block(input_tensor, kernel_size, filters, stage=stage,\n",
    "                          strides=conv_strides, block='block_0',\n",
    "                          training=training)\n",
    "  for i in range(size - 1):\n",
    "    x = identity_building_block(x, kernel_size, filters, stage=stage,\n",
    "                                block='block_%d' % (i + 1), training=training)\n",
    "  return x\n",
    "\n",
    "def resnet(num_blocks, classes=10, training=None):\n",
    "  \"\"\"Instantiates the ResNet architecture.\n",
    "\n",
    "  Arguments:\n",
    "    num_blocks: integer, the number of conv/identity blocks in each block.\n",
    "      The ResNet contains 3 blocks with each block containing one conv block\n",
    "      followed by (layers_per_block - 1) number of idenity blocks. Each\n",
    "      conv/idenity block has 2 convolutional layers. With the input\n",
    "      convolutional layer and the pooling layer towards the end, this brings\n",
    "      the total size of the network to (6*num_blocks + 2)\n",
    "    classes: optional number of classes to classify images into\n",
    "    training: Only used if training keras model with Estimator.  In other\n",
    "    scenarios it is handled automatically.\n",
    "\n",
    "  Returns:\n",
    "    A Keras model instance.\n",
    "  \"\"\"\n",
    "\n",
    "  input_shape = (32, 32, 3)\n",
    "  img_input = layers.Input(shape=input_shape)\n",
    "\n",
    "  if backend.image_data_format() == 'channels_first':\n",
    "    x = layers.Lambda(lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),\n",
    "                      name='transpose')(img_input)\n",
    "    bn_axis = 1\n",
    "  else:  # channel_last\n",
    "    x = img_input\n",
    "    bn_axis = 3\n",
    "\n",
    "  x = tf.keras.layers.ZeroPadding2D(padding=(1, 1), name='conv1_pad')(x)\n",
    "  x = tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                             strides=(1, 1),\n",
    "                             padding='valid',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             bias_regularizer=\n",
    "                             tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                             name='conv1')(x)\n",
    "  x = tf.keras.layers.BatchNormalization(axis=bn_axis, name='bn_conv1',\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(\n",
    "                                             x, training=training)\n",
    "  x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[16, 16],\n",
    "                   stage=2, conv_strides=(1, 1), training=training)\n",
    "\n",
    "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[32, 32],\n",
    "                   stage=3, conv_strides=(2, 2), training=training)\n",
    "\n",
    "  x = resnet_block(x, size=num_blocks, kernel_size=3, filters=[64, 64],\n",
    "                   stage=4, conv_strides=(2, 2), training=training)\n",
    "\n",
    "  x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "  x = tf.keras.layers.Dense(classes, activation='softmax',\n",
    "                            kernel_initializer='he_normal',\n",
    "                            kernel_regularizer=\n",
    "                            tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                            bias_regularizer=\n",
    "                            tf.keras.regularizers.l2(L2_WEIGHT_DECAY),\n",
    "                            name='fc10')(x)\n",
    "\n",
    "  inputs = img_input\n",
    "  # Create model.\n",
    "  model = tf.keras.models.Model(inputs, x, name='resnet56')\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "resnet20 = functools.partial(resnet, num_blocks=3)\n",
    "resnet32 = functools.partial(resnet, num_blocks=5)\n",
    "resnet56 = functools.partial(resnet, num_blocks=9)\n",
    "resnet110 = functools.partial(resnet, num_blocks=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cifar10/3.0.0 (download: 162.17 MiB, generated: Unknown size, total: 162.17 MiB) to /home/mao/tensorflow_datasets/cifar10/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1217212e4cb04414af474facf67e2555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dd27cabe9c4cd998b4046feace5e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86d49c0850e464996bbfd2862e2efc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cs.toronto.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Shuffling and writing examples to /home/mao/tensorflow_datasets/cifar10/3.0.0.incompleteVOJ9DK/cifar10-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21265e6599e48adb1f7c373bbaec0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Shuffling and writing examples to /home/mao/tensorflow_datasets/cifar10/3.0.0.incompleteVOJ9DK/cifar10-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f483b92a0ff7402490f3b35155fc323f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar10 downloaded and prepared to /home/mao/tensorflow_datasets/cifar10/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cifar_builder = tfds.builder('cifar10')\n",
    "cifar_builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-ba7afe14e3c8>:24: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-ba7afe14e3c8>:24: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def preprocess_data(record):\n",
    "  image = record['image']\n",
    "  label = record['label']\n",
    "  \n",
    "  # Resize the image to add four extra pixels on each side.\n",
    "  image = tf.image.resize_with_crop_or_pad(\n",
    "      image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "  # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "  image = tf.image.random_crop(image, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "\n",
    "  # Randomly flip the image horizontally.\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  image = tf.image.per_image_standardization(image)\n",
    "  \n",
    "  label = tf.compat.v1.sparse_to_dense(label, (NUM_CLASSES,), 1)\n",
    "  return image, label\n",
    "\n",
    "train_data = cifar_builder.as_dataset(split=tfds.Split.TRAIN)\n",
    "train_data = train_data.repeat()\n",
    "train_data = train_data.map(\n",
    "    lambda value: preprocess_data(value))\n",
    "train_data = train_data.shuffle(1024)\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "model = resnet56(classes=NUM_CLASSES)\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 steps\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 10s 486ms/step - loss: 3.6656 - categorical_accuracy: 0.1234\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 3.1418 - categorical_accuracy: 0.1418\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 3s 163ms/step - loss: 3.0695 - categorical_accuracy: 0.1719\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 3.0567 - categorical_accuracy: 0.1758\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 3.0105 - categorical_accuracy: 0.1813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1fec138b70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,\n",
    "          steps_per_epoch=20,\n",
    "          epochs=5, \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cifar_builder.as_dataset(split=tfds.Split.TRAIN)\n",
    "train_data = train_data.repeat()\n",
    "train_data = train_data.map(\n",
    "    lambda value: preprocess_data(value))\n",
    "train_data = train_data.shuffle(1024)\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "# It will prefetch the data in (s-1) step\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 steps\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 9s 425ms/step - loss: 2.9733 - categorical_accuracy: 0.1945\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 3s 130ms/step - loss: 2.8966 - categorical_accuracy: 0.2336\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 2.9219 - categorical_accuracy: 0.2266\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 3s 131ms/step - loss: 2.8785 - categorical_accuracy: 0.2305\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 3s 130ms/step - loss: 2.8437 - categorical_accuracy: 0.2621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f84736828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 3)\n",
    "\n",
    "model.fit(train_data,\n",
    "          steps_per_epoch=20,\n",
    "          epochs=5, \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
